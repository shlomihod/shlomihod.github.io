<img class="profile-photo" src="static/images/profile.png" />

<div class="contact">
    <small>he/him/his</small>
    <br />
    <i class="fas fa-envelope"></i> shlomi &lt;AT&gt; bu &lt;DOT&gt; edu
    <br />
    <a href="https://www.linkedin.com/in/shlomi-hod/"><i class="fab fa-linkedin"></i></a>
    <a href="https://github.com/shlomihod"><i class="fab fa-github"></i></a>
</div>

I'm an incoming CS PhD student at Boston University being supervised by [Prof. Ran Canetti](http://www.bu.edu/cs/profiles/ran-canetti/).

I'm interested in **responsible AI**, particularly:
1. Bias, fairness and societal impact of algorithms and machine learning systems
2. Interpretable machine learning

In summer 2019 I did a reseach internship at the [Center for Human-Compatible AI](https://humancompatible.ai/) at UC Berkeley, working on neural network interpretability. 

Occasionally, I'm consulting to startups and companies with data science projects.

In my previous life I was a social entrepreneur - co-founder of the [Israeli Cyber Education Center](https://cyber.org.il/about-us-eng/). There I led the development of nationwide educational programs in computing for kids and teens. The center aims to increase the social mobility of underrepresented groups in tech, such as women, minorities, and individuals from the suburbs of Israel. I co-authored a [Computer Network textbook](https://data.cyber.org.il/networks/networks.pdf) in tutorial approach (in Hebrew).  
Before that I was an algorithmic research team leader in cybersecurity.